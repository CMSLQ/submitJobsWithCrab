--------- Instructions --------------

**** NOTE ****


- template_crab.cfg to retrieve the output on your machine

- template_crab_copyTo_UMD_SE.cfg to copy output to SE in UMD (and also for publication on local DBS)

- template_crab_caf_castor.cfg, template_crab_castor.cfg, 
  and createJobsWithCrabCastor.pl are NOT updated!


**************

1) setup LCG environment and crab

source /afs/cern.ch/cms/LCG/LCG-2/UI/cms_ui_env.csh 
source /afs/cern.ch/cms/ccs/wm/scripts/Crab/crab.csh


2) go in your CMSSW release and set the cmssw environment

cd CMSSW_X_Y_Z/src
cmsenv


3) test in local your personal myCMSSW_cfg.py config file 

cmsRun myCMSSW_cfg.py


4) modify your CMSSW config file for submission with crab

The only thing you should change in myCMSSW_cfg.py is the name 
of the output file;
instead of the output filename you had before, put "THISROOTFILE"

example:
process.treeCreator.rootfile = cms.untracked.string("THISROOTFILE")


((( Change directory to /submitJobsWithCrab )))


For the moment remeber to change also createJobsWithCrab.pl 
at #%%%%%%%%%%%%% IMPORTANT %%%%%%%%%%%%% 
It will be fixed soon.

5) create input list 

create an input list with datasets that you want to analyze. 
The format of the text file is: 

dataset_name   total_number_of_events     number_of_jobs

example (inputList.txt):

/QCDDiJetPt120to170/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 20 2
/QCDDiJetPt170to230/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 30 3


6) Create the crab jobs 

Follow instructions generated with ./createJobsWithCrab.pl to create jobs. 

Usage: ./createJobsWithCrab.pl -d <storageDir> -v <tagname> -p <publishname> -i <inputList> -t <templateCrab> -c <myCMSSWconfig> [-h <help?>]

Example: ./createJobsWithCrab.pl -d /home/santanas/Data/test/RootNtuples -v V00-00-05 -p LQrtTuple -i inputList.txt -t template_crab.cfg -c myCMSSW_cfg.py

NOTE: -p option is mandatory, but only used if the template contains the crab options for publication (as in template_crab_copyTo_UMD_SE.cfg)
         --> IMPORTANT : please MAX 10 characters for option "p".

This command will create the following directory structure:

/home/santanas/Data/test/RootNtuples/V00-00-05_currentDateAndTime 
(in the jargon of this scirpt 
this is the so-called "production directory" or prodDir)

  --> cfgfiles (it will contain the crab and cmssw for each crab job created) 
  --> output (it will contain the final output, i.e. .root files)
  --> workdir 
      --> dataset_1 (i.e. QCDDiJetPt120to170__Summer08_IDEAL_V9_v1__GEN-SIM-RECO)
      --> dataset_2 (i.e. QCDDiJetPt170to230__Summer08_IDEAL_V9_v1__GEN-SIM-RECO)
      ....
      --> dataset_N

     (each of these directories is the ui working directory 
      that crab usually needs to perform his job. 
      After retrieving the output, the log files STDERR and STDOUT 
      of the cmssw jobs will be copied for each dataset in the directory "res")

NOTE: the input list will be also copied in the "prodDir"
(i.e. /home/santanas/Data/test/RootNtuples/V00-00-05_currentDateAndTime)

NOTE 2: in case of copy in UMD SE (i.e. using for example template_crab_copyTo_UMD_SE.cfg) 
        the output of the job will be stored at:


                                         MAX 25 characters
                                       -----------------------
store/user/santanas/QCDDiJetPt120to170/LQrtTuple_091002_094727/0dc4992a12730eb413f8060b80f4a776
           --> user
                    --> original name of dataset processed
                                       --> publishname
                                                 --> currentDateAndTime
                                                               --> random string generated by crab

7) do other actions (submit/getouput/...) after the creation of the jobs  

After creating the jobs you can use the script 

./postCreationCommandsWithCrab.pl 

to make the following actions:

   - status
   - submit
   - getouput
   - kill
   - resubmit

The status of the jobs (crab -status) will be summarized automatically in two files
, independetly from which action you do:

   - statusCrab.log   (the full output from the "crab -status" command)
   - statusReport.log (status report summary)

See the help (just run ./postCreationCommandsWithCrab.pl with no options) for details.

NOTE: For the moment you can apply these actions on all the jobs created, you cannot 
specify a sub-set of the jobs. Anyway for particular cases, you can always look 
at the status report and apply by hand a specific action that you need
on a single dataset or a single job.

P.S. please give me feedback (francesco.santanastasio@cern.ch)
